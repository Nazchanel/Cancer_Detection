{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d20dca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47d20dca",
    "outputId": "87207813-49bc-422f-9106-ef1ba0e1bff8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sks\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import keras\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from google.colab import drive\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MEIuI-4_K-8_",
   "metadata": {
    "id": "MEIuI-4_K-8_"
   },
   "outputs": [],
   "source": [
    "os.chdir(r\"/content/drive/MyDrive/Skin_Cancer/train\")\n",
    "train_benign = os.path.join(\"benign\")\n",
    "train_malignant = os.path.join(\"malignant\")\n",
    "\n",
    "os.chdir(r\"/content/drive/MyDrive/Skin_Cancer/test\")\n",
    "test_benign = os.path.join(\"benign\")\n",
    "test_malignant = os.path.join(\"malignant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce6d14",
   "metadata": {
    "id": "88ce6d14"
   },
   "outputs": [],
   "source": [
    "img_height, img_width = 254,254\n",
    "nb_train_samples = 65\n",
    "nb_validation_samples = 10\n",
    "epochs = 5\n",
    "batch_size = 5  \n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124e52d",
   "metadata": {
    "id": "d124e52d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96122f6c",
   "metadata": {
    "id": "96122f6c"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/content/drive/MyDrive/Skin_Cancer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb87b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62eb87b7",
    "outputId": "a78f2f14-6873-4cd6-c626-7ac9dab38d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2622 images belonging to 2 classes.\n",
      "Found 660 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(img_height, img_width), batch_size=batch_size, class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 19 using valid_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory('test',\n",
    "        target_size=(img_height, img_width), \n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24077fc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24077fc1",
    "outputId": "098930fd-d779-45da-e6c0-cc3d2b39e33b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 0s 0us/step\n",
      "87924736/87910968 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input\n",
    "from keras.layers import Dense, Conv2D, Flatten, ZeroPadding2D \n",
    "from keras.layers import MaxPooling2D, Dropout, Input, BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "model_top = Sequential()\n",
    "model_top.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:], data_format=None)),  \n",
    "model_top.add(Dense(256, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=model_top(base_model.output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d9628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a19d9628",
    "outputId": "dc990441-628d-43f9-8b40-fc6d92e54502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 66s 4s/step - loss: 0.6468 - accuracy: 0.6923 - val_loss: 1.1869 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.5501 - accuracy: 0.6923 - val_loss: 0.9953 - val_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 43s 3s/step - loss: 0.4947 - accuracy: 0.7538 - val_loss: 1.9518 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 43s 3s/step - loss: 0.6282 - accuracy: 0.7077 - val_loss: 2.0555 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 42s 3s/step - loss: 0.6146 - accuracy: 0.7385 - val_loss: 1.4951 - val_accuracy: 0.2000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08,decay=0.0), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HWWfw4N1tGcy",
   "metadata": {
    "id": "HWWfw4N1tGcy"
   },
   "outputs": [],
   "source": [
    "img_path = '/content/drive/MyDrive/Skin_Cancer/Malignant/1491.jpg'  \n",
    "img_path2 = '/content/drive/MyDrive/Skin_Cancer/Benign/1792.jpg'\n",
    "img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "img2 = image.load_img(img_path2, target_size=(img_width, img_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dXNw5Kv_voe2",
   "metadata": {
    "id": "dXNw5Kv_voe2"
   },
   "outputs": [],
   "source": [
    "# Malignant\n",
    "img = image.img_to_array(img)\n",
    "x = np.expand_dims(img, axis=0) * 1./255\n",
    "score = model.predict(x)\n",
    "print('Predicted:', score[0], 'Benign' if score > .50 and score < .90 else 'Malignant')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aAKjjM4D3-lM",
   "metadata": {
    "id": "aAKjjM4D3-lM"
   },
   "outputs": [],
   "source": [
    "# Benign\n",
    "img = image.img_to_array(img2)\n",
    "x = np.expand_dims(img, axis=0) * 1./255\n",
    "score = model.predict(x)\n",
    "print('Predicted:', score[0], 'Benign' if score > .50 and score < .90 else 'Malignant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0FQT0aeMEaQh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FQT0aeMEaQh",
    "outputId": "f19874ac-aa9c-4659-f386-cad2729633c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Skin_Cancer/Malignant/1493.jpg is Malignant\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eAZgsFhaD7yC",
   "metadata": {
    "id": "eAZgsFhaD7yC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0MlSb0LqD7u9",
   "metadata": {
    "id": "0MlSb0LqD7u9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Skin_Cancer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
